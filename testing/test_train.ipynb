{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "from mol_td.utils import load_config\n",
    "from mol_td.data_fns import load_data, prep_data, get_split, prep_dataloaders\n",
    "from mol_td.model import SimpleVAE\n",
    "\n",
    "import jax\n",
    "from jax import jit\n",
    "from typing import Any, Callable, Sequence, Optional\n",
    "from jax import lax, random as rnd, numpy as jnp\n",
    "import flax\n",
    "from flax.core import freeze, unfreeze\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WANDB': {'user': 'xmax1', 'WANDB_API_KEY': 1},\n",
       " 'MODEL': {'enc_hidden': [40, 20], 'dec_hidden': [40, 84], 'seed': 1},\n",
       " 'TRAIN': {'n_epochs': 3, 'lr': 0.001},\n",
       " 'PATHS': {'root': '/home/amawi/projects/mol-td',\n",
       "  'data': './data',\n",
       "  'results': './results/test',\n",
       "  'default_config': './configs/default_config.yaml',\n",
       "  'uracil_xyz': './data/uracil.xyz'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = load_config('/home/amawi/projects/mol-td/configs/default_config.yaml')\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133770, 12, 3) (133770, 12, 3) (133770, 12, 1)\n",
      "['E', 'name', 'F', 'theory', 'R', 'z', 'type', 'md5']\n"
     ]
    }
   ],
   "source": [
    "# load and prep the data\n",
    "data, raw_data = load_data('/home/amawi/projects/mol-td/data/uracil_dft.npz')\n",
    "print(list(raw_data.keys()))\n",
    "train_loader, val_loader, test_loader = prep_dataloaders(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions:  {'mu': (32, 20), 'sigma': (32, 20), 'predicted': (32, 84)}\n"
     ]
    }
   ],
   "source": [
    "# initialise the model\n",
    "model = SimpleVAE(cfg['MODEL'])\n",
    "rng, video_rng, params_rng, sample_rng = rnd.split(rnd.PRNGKey(cfg['MODEL']['seed']), 4)\n",
    "ex_batch = next(train_loader)\n",
    "params = model.init(dict(params=params_rng, sample=sample_rng), ex_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxmax1\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/amawi/projects/mol-td/testing/wandb/run-20220404_163310-test3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xmax1/test/runs/test3\" target=\"_blank\">test3</a></strong> to <a href=\"https://wandb.ai/xmax1/test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions:  {'mu': (32, 20), 'sigma': (32, 20), 'predicted': (32, 84)}\n",
      "Dimensions:  {'mu': (32, 20), 'sigma': (32, 20), 'predicted': (32, 84)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>kl_div</td><td>█▇▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▅▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nll</td><td>█▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>kl_div</td><td>0.2171</td></tr><tr><td>loss</td><td>214.48035</td></tr><tr><td>nll</td><td>214.26324</td></tr><tr><td>val_loss</td><td>214.48035</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">test3</strong>: <a href=\"https://wandb.ai/xmax1/test/runs/test3\" target=\"_blank\">https://wandb.ai/xmax1/test/runs/test3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220404_163310-test3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = load_config('/home/amawi/projects/mol-td/configs/default_config.yaml')\n",
    "\n",
    "run = wandb.init(project='test', id='test3', entity='xmax1', config=cfg['TRAIN'])\n",
    "\n",
    "loss_grad_fn = jit(jax.value_and_grad(model.apply, has_aux=True))\n",
    "fwd = jit(model.apply)\n",
    "\n",
    "tx = optax.sgd(learning_rate=cfg['TRAIN']['lr'])\n",
    "opt_state = tx.init(params)\n",
    "\n",
    "for epoch in range(cfg['TRAIN']['n_epochs']):\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        (loss, signal), grads = loss_grad_fn(params, batch)\n",
    "        updates, opt_state = tx.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "\n",
    "        wandb.log({'loss': loss, \n",
    "                   'kl_div': signal['kl_div'], \n",
    "                   'nll': signal['nll']})\n",
    "\n",
    "        # if batch_idx % 100 == 0:\n",
    "        #     print(f'Step {batch_idx}, loss {loss}')\n",
    "\n",
    "        # indicators TODO\n",
    "\n",
    "    train_loader.shuffle()\n",
    "\n",
    "    if val_loader is not None:\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            val_loss, _ = fwd(params, batch)\n",
    "            \n",
    "        wandb.log({'val_loss': loss, 'epoch': epoch})\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_loader:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a176005efc6340d6f651f92e427305c0c77418f591408071800ce94934a5505a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('td')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

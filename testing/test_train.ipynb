{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mol_td.utils import load_config\n",
    "from mol_td.data_fns import load_data, prep_data, get_split, prep_data_torch\n",
    "import jax\n",
    "from typing import Any, Callable, Sequence, Optional\n",
    "from jax import lax, random as rnd, numpy as jnp\n",
    "import flax\n",
    "from flax.core import freeze, unfreeze\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WANDB': {'user': 'xmax1'},\n",
       " 'TRAIN': {'n_epochs': 1000, 'lr': 0.001},\n",
       " 'PATHS': {'root': '/home/amawi/projects/mol-td',\n",
       "  'data': './data',\n",
       "  'results': './results/test',\n",
       "  'default_config': './configs/default_config.yaml',\n",
       "  'uracil_xyz': './data/uracil.xyz'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = load_config('/home/amawi/projects/mol-td/configs/default_config.yaml')\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133770, 12, 3) (133770, 12, 3) (133770, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "# load and prep the data\n",
    "data, raw_data = load_data('/home/amawi/projects/mol-td/data/uracil_dft.npz')\n",
    "\n",
    "# train_loader, val_loader, test_loader = prep_data(data, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 17:37:07.785463: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/home/amawi/.conda/envs/td/lib/python3.10/site-packages/jax/_src/random.py:371: FutureWarning: jax.random.shuffle is deprecated and will be removed in a future release. Use jax.random.permutation with independent=True.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/amawi/projects/mol-td/testing/test_train.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btitan02.compute.dtu.dk/home/amawi/projects/mol-td/testing/test_train.ipynb#ch0000008vscode-remote?line=0'>1</a>\u001b[0m train_loader \u001b[39m=\u001b[39m prep_data_torch(data, data)\n",
      "File \u001b[0;32m~/projects/mol-td/mol_td/data_fns.py:92\u001b[0m, in \u001b[0;36mprep_data_torch\u001b[0;34m(data, target, batch_size, data_seed)\u001b[0m\n\u001b[1;32m     <a href='file:///home/amawi/projects/mol-td/mol_td/data_fns.py?line=88'>89</a>\u001b[0m idxs \u001b[39m=\u001b[39m get_split(\u001b[39mlen\u001b[39m(data), data_seed\u001b[39m=\u001b[39mdata_seed)\n\u001b[1;32m     <a href='file:///home/amawi/projects/mol-td/mol_td/data_fns.py?line=89'>90</a>\u001b[0m train_idxs, val_idxs, test_idxs \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(np\u001b[39m.\u001b[39marray, idxs)\n\u001b[0;32m---> <a href='file:///home/amawi/projects/mol-td/mol_td/data_fns.py?line=91'>92</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m TensorDataset(data[train_idxs], target[train_idxs])\n\u001b[1;32m     <a href='file:///home/amawi/projects/mol-td/mol_td/data_fns.py?line=92'>93</a>\u001b[0m \u001b[39m# val_dataset = TensorDataset(*[jnp.array(input) for input in [data[val_idxs], target[val_idxs]]], )\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/amawi/projects/mol-td/mol_td/data_fns.py?line=93'>94</a>\u001b[0m \u001b[39m# test_dataset = TensorDataset(*[jnp.array(input) for input in [data[test_idxs], target[test_idxs]]], )\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/amawi/projects/mol-td/mol_td/data_fns.py?line=95'>96</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/td/lib/python3.10/site-packages/torch/utils/data/dataset.py:365\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    <a href='file:///home/amawi/.conda/envs/td/lib/python3.10/site-packages/torch/utils/data/dataset.py?line=363'>364</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mtensors: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/amawi/.conda/envs/td/lib/python3.10/site-packages/torch/utils/data/dataset.py?line=364'>365</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39;49m(tensors[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m) \u001b[39m==\u001b[39;49m tensor\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m tensor \u001b[39min\u001b[39;49;00m tensors), \u001b[39m\"\u001b[39m\u001b[39mSize mismatch between tensors\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/amawi/.conda/envs/td/lib/python3.10/site-packages/torch/utils/data/dataset.py?line=365'>366</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors \u001b[39m=\u001b[39m tensors\n",
      "File \u001b[0;32m~/.conda/envs/td/lib/python3.10/site-packages/torch/utils/data/dataset.py:365\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///home/amawi/.conda/envs/td/lib/python3.10/site-packages/torch/utils/data/dataset.py?line=363'>364</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mtensors: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/amawi/.conda/envs/td/lib/python3.10/site-packages/torch/utils/data/dataset.py?line=364'>365</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(tensors[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m) \u001b[39m==\u001b[39m tensor\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m tensors), \u001b[39m\"\u001b[39m\u001b[39mSize mismatch between tensors\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/amawi/.conda/envs/td/lib/python3.10/site-packages/torch/utils/data/dataset.py?line=365'>366</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors \u001b[39m=\u001b[39m tensors\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "train_loader = prep_data_torch(data, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_batches = len(val_idxs) // batch_size\n",
    "n_remainder = len(val_idxs) - n_batches * batch_size\n",
    "val_idxs = val_idxs[:-n_remainder]\n",
    "val_idxs = val_idxs.reshape((n_batches, batch_size))\n",
    "print(val_idxs.shape)\n",
    "\n",
    "\n",
    "\n",
    "# train_loader = [data[train_idxs], data[train_idxs]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E', 'name', 'F', 'theory', 'R', 'z', 'type', 'md5']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a forward pass with wandb\n",
    "\n",
    "\n",
    "def test_train(model, params, train_loader, val_loader=None, cfg=None):\n",
    "\n",
    "    if cfg is None: cfg = load_config()  # loads default\n",
    "\n",
    "    run = wandb.init(project=cfg['PATHS']['results'], entity=cfg['WANDB']['user'], config=cfg['TRAIN'])\n",
    "\n",
    "    loss_grad_fn = jax.value_and_grad(loss_fn)\n",
    "\n",
    "    tx = optax.sgd(learning_rate=cfg['TRAIN']['lr'])\n",
    "    opt_state = tx.init(params)\n",
    "\n",
    "    for epoch in range(cfg['TRAIN']['n_epochs']):\n",
    "        for batch_idx, (batch, target) in enumerate(train_loader):\n",
    "            \n",
    "            loss, grads = loss_grad_fn(params, batch, target)\n",
    "            updates, opt_state = tx.update(grads, opt_state)\n",
    "            params = optax.apply_updates(params, updates)\n",
    "\n",
    "            wandb.log({'loss': loss})\n",
    "\n",
    "            # indicators TODO\n",
    "\n",
    "        if val_loader is not None:\n",
    "            for batch_idx, (batch, target) in enumerate(train_loader):\n",
    "\n",
    "                val_loss = loss_fn(batch)\n",
    "\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a176005efc6340d6f651f92e427305c0c77418f591408071800ce94934a5505a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('td')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
